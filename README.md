
# Emotiona.ai : Facial Emotion Recognition (FER-2013) Project

This project utilizes the FER-2013 dataset to recognize facial emotions. It consists of two main components:

## Real-Time Recognition:
- Real-time detection and recognition of facial emotions.

## Input-Based Recognition:
- Allows users to select an image or video file from their system for emotion recognition.

### Dataset:
The FER-2013 dataset is a publicly available dataset containing grayscale images of faces labeled with one of seven emotions: angry, disgust, fear, happy, sad, surprise, or neutral. You can find more information and download the dataset here.

### Model:
The model used in this project achieves an accuracy of approximately 65%. You can download the model from here.

## Usage:

### Real-Time Recognition:
1. Navigate to the `realtime` directory : Real-Time.
2. Run the real-time recognition script.
3. The script will start a real-time video feed, detecting and recognizing emotions in faces.

### Input-Based Recognition:
1. Navigate to the `input_based` directory : Input-Based.
2. Run the input-based recognition script.
3. Follow the instructions to select an image or video file from your system for emotion recognition.

### Personal Test Images and Videos:
Please note that the project repository contains personal test images and videos. These are intended for demonstration purposes only and should not be used for any other works without proper permission.

## Report:
For more details about the project, including methodology, results, and analysis, please refer to the Project Report.
